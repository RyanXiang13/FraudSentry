{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Detection using Machine Learning\n",
    "##### using a logistic regression model to predict binary outcome of wheteher fraud is detected in a statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING THE FOLLOWING FEATURES:\n",
    "# amt, gender, state, city_pop, job, dob, is_fraud\n",
    "\n",
    "data = pd.read_csv('./data/fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X = data[['amt', 'gender', 'state', 'city_pop', 'job', 'age']]\n",
    "y = data['is_fraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t-0.4375949400472785\n",
      "  (0, 1)\t-0.29312495132245125\n",
      "  (0, 2)\t-1.3086119749306617\n",
      "  (0, 4)\t1.0\n",
      "  (0, 336)\t1.0\n",
      "  (0, 516)\t1.0\n",
      "  (1, 0)\t-0.4108434284736928\n",
      "  (1, 1)\t-0.20241725804365865\n",
      "  (1, 2)\t-0.6178910278309626\n",
      "  (1, 3)\t1.0\n",
      "  (1, 309)\t1.0\n",
      "  (1, 549)\t1.0\n",
      "  (2, 0)\t-0.41026327521065126\n",
      "  (2, 1)\t-0.21646343056437217\n",
      "  (2, 2)\t-0.5027708699810127\n",
      "  (2, 4)\t1.0\n",
      "  (2, 102)\t1.0\n",
      "  (2, 514)\t1.0\n",
      "  (3, 0)\t-0.29268554723421686\n",
      "  (3, 1)\t0.08944128992208188\n",
      "  (3, 2)\t-0.5603309489059877\n",
      "  (3, 3)\t1.0\n",
      "  (3, 73)\t1.0\n",
      "  (3, 544)\t1.0\n",
      "  (4, 0)\t-0.28759309081418494\n",
      "  :\t:\n",
      "  (907667, 547)\t1.0\n",
      "  (907668, 0)\t-0.437917247415635\n",
      "  (907668, 1)\t-0.27699369664149986\n",
      "  (907668, 2)\t0.5333105506685357\n",
      "  (907668, 3)\t1.0\n",
      "  (907668, 275)\t1.0\n",
      "  (907668, 505)\t1.0\n",
      "  (907669, 0)\t0.30944907832931007\n",
      "  (907669, 1)\t-0.2939656034949916\n",
      "  (907669, 2)\t-0.2725305542811131\n",
      "  (907669, 3)\t1.0\n",
      "  (907669, 444)\t1.0\n",
      "  (907669, 531)\t1.0\n",
      "  (907670, 0)\t-0.4168383455251229\n",
      "  (907670, 1)\t-0.29452824471283356\n",
      "  (907670, 2)\t1.799632287017984\n",
      "  (907670, 4)\t1.0\n",
      "  (907670, 154)\t1.0\n",
      "  (907670, 522)\t1.0\n",
      "  (907671, 0)\t0.45422954819502903\n",
      "  (907671, 1)\t-0.29323747956601964\n",
      "  (907671, 2)\t-0.9056914224558372\n",
      "  (907671, 3)\t1.0\n",
      "  (907671, 31)\t1.0\n",
      "  (907671, 539)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Separate the features that require encoding\n",
    "string_features = ['gender', 'job', 'state']\n",
    "numeric_features = ['amt', 'city_pop', 'age']\n",
    "\n",
    "# Create column transformer to encode\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('str', OneHotEncoder(handle_unknown='ignore'), string_features)\n",
    "    ]\n",
    ")\n",
    "preprocessor.fit(X_train)\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "print(X_train_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features after preprocessing\n",
    "num_features = X_train_processed.shape[1]\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Input(shape=(num_features,)),  # Define input layer explicitly\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0279 - val_accuracy: 0.9949 - val_loss: 0.0197\n",
      "Epoch 2/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0191 - val_accuracy: 0.9950 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0180 - val_accuracy: 0.9950 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0174 - val_accuracy: 0.9951 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0171 - val_accuracy: 0.9954 - val_loss: 0.0181\n",
      "Epoch 6/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0165 - val_accuracy: 0.9953 - val_loss: 0.0181\n",
      "Epoch 7/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0162 - val_accuracy: 0.9953 - val_loss: 0.0181\n",
      "Epoch 8/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0161 - val_accuracy: 0.9954 - val_loss: 0.0178\n",
      "Epoch 9/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0168 - val_accuracy: 0.9954 - val_loss: 0.0187\n",
      "Epoch 10/10\n",
      "\u001b[1m28365/28365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0166 - val_accuracy: 0.9953 - val_loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "# Define early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # Stop if no large change in 5 consecutive epochs\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_processed, y_train,\n",
    "    epochs=10,  # Number of epochs\n",
    "    batch_size=32,  # Batch size for training\n",
    "    validation_data=(X_val_processed, y_val),\n",
    "    callbacks=[early_stopping]  # Use early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12157/12157 - 9s - 703us/step - accuracy: 0.9954 - loss: 0.0178\n",
      "Validation Loss: 0.017841769382357597\n",
      "Validation Accuracy: 0.9953547716140747\n",
      "\u001b[1m12157/12157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step\n",
      "Confusion Matrix:\n",
      "tf.Tensor(\n",
      "[[386276    442]\n",
      " [  1365    920]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    386718\n",
      "           1       0.68      0.40      0.50      2285\n",
      "\n",
      "    accuracy                           1.00    389003\n",
      "   macro avg       0.84      0.70      0.75    389003\n",
      "weighted avg       0.99      1.00      0.99    389003\n",
      "\n",
      "Accuracy: 0.995354791608291\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val_processed, y_val, verbose=2)\n",
    "\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Predict on the validation data\n",
    "y_pred_prob = model.predict(X_val_processed)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Evaluate the model\n",
    "print('Confusion Matrix:')\n",
    "print(tf.math.confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('./model/fraud_detection_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
